{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Classification using k Nearest Neighbor\n",
    "\n",
    "# Background\n",
    "\n",
    "## Motivation\n",
    "\n",
    "I am currently working on feature extraction and identification using simple k nearest neighbor clustering algorithms over a data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Information\n",
    "\n",
    "We're using a dataset that has been pre-captured, cleaned and labeled by an ongoing effort found here : https://stratosphereips.org/category/dataset.html\n",
    "\n",
    "They're currently working to on a machine learning effort for Malware classification, much like the example we're showing here.\n",
    "\n",
    "The dataset currently contains typical Netflow capture information, including time stamps, durations of the flows, Src/DstIP's, Src/Dst Port, and other flow related information. The key to the provided dataset was that it is labeled. We can then use these labels to start to train a model to identify and classify unlabeled flows as any of the labels provided in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Class for formatting of the TimeStamp field contained within the netflow captures\n",
    "\n",
    "setClass(\"myPosixCt\")\n",
    "setAs(\"character\", \"myPosixCt\", function(from) as.POSIXct(from, format = \"%Y/%m/%d %H:%M:%OS\"))\n",
    "options(set.seconds=\"6\")\n",
    "\n",
    "# Read .binetflow file into dataframe\n",
    "\n",
    "flowdata_csv <- read.csv(\"capture20110810.binetflow\", colClasses = c(\"myPosixCt\", \"numeric\", \"factor\", \"factor\",\"factor\",\"factor\",\"factor\",\"factor\",\"factor\",\"factor\",\"factor\",\"numeric\", \"numeric\", \"numeric\", \"factor\"), strip.white = TRUE, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(caret)\n",
    "library(pander)\n",
    "library(doMC)\n",
    "library(dplyr)\n",
    "library(Matrix)\n",
    "library(plyr)\n",
    "\n",
    "\n",
    "# Register CPU core count\n",
    "registerDoMC(cores=23)\n",
    "\n",
    "# Utility function for use with % frequency tables\n",
    "frqtab <- function(x, caption) {\n",
    "    round(100*prop.table(table(x)), 3)\n",
    "}\n",
    "\n",
    "# Utility function to round values in a list\n",
    "# but only if they are numeric\n",
    "\n",
    "round_numeric <- function(lst, decimals=2) {\n",
    "    lappy(lst, function(x){\n",
    "        if (is.numeric(x)) {\n",
    "            x <- round(x, decimals)\n",
    "        }\n",
    "        return(x)\n",
    "    })\n",
    "}\n",
    "\n",
    "# Utility function for model comparison\n",
    "\n",
    "summod <- function(cm, fit) {\n",
    "    summ <- list(k = fit$finalModel$k,\n",
    "                metric = fit$metric,\n",
    "                value = fit$results[fit$resultes$k == fit$finalModel$k, fit$metric],\n",
    "                TN = cm$table[1,1], # True negatives\n",
    "                TP = cm$table[2,2], # True positives\n",
    "                FN = cm$table[1,2], # False negatives\n",
    "                FP = cm$table[2,1], # False positives\n",
    "                acc = cm$overall[\"Accuracy\"], \n",
    "                sens = cm$byClass[\"Sensitivity\"],\n",
    "                spec = cm$byClass[\"Specificity\"],\n",
    "                PPV = cm$byClass[\"Positive Predicted Value\"],\n",
    "                NPV = cm$byClass[\"Negative Prediced Value\"])\n",
    "    round_numeric(summ)\n",
    "}\n",
    "\n",
    "# Utility function to normalize the data\n",
    "\n",
    "normalize <- function(x){\n",
    "    num <- x - min(x)\n",
    "    denom <- max(x) - min(x)\n",
    "    return (num/denom)\n",
    "}\n",
    "\n",
    "#Function to timeslice the data however user would like\n",
    "\n",
    "timeslice <- function(df, slice, interval) {\n",
    "    if (slice == 'secs'){\n",
    "        df <- subset(df, df$StartTime <= df$StartTime[1] + (interval))\n",
    "        return(df)\n",
    "    }\n",
    "    else if (slice == 'mins'){\n",
    "        df <- subset(df, df$StartTime <= df$StartTime[1] + (interval * 60))\n",
    "        return(df)\n",
    "    }\n",
    "    else if (slice == 'hours') {\n",
    "        df <- subset(df, df$StartTime <= df$StartTime[1] + (interval * 3600))\n",
    "        return(df)\n",
    "    }\n",
    "    else if (slice == 'days'){\n",
    "        df <- subset(df, df$StartTime <= df$StartTime[1] + (interval * 86400))\n",
    "        return(df)\n",
    "    }\n",
    "    else\n",
    "      error <- print(\"Please enter a valid time interval.\")\n",
    "      return(error)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Subset and normalize data\n",
    "\n",
    "# Set labels to char for subsetting\n",
    "flowdata_csv$Label <- as.character(flowdata_csv$Label)\n",
    "\n",
    "#Function to carve up by timeslice / interval\n",
    "\n",
    "flowdata_slice <- timeslice(flowdata_csv, 'mins', 118)\n",
    "\n",
    "str(flowdata_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# One hot encode categorical vars\n",
    "test_sparse_model <- fac2sparse(flowdata_csv$Proto)\n",
    "\n",
    "sparseMatrix(test_sparse_model)\n",
    "\n",
    "str(test_sparse_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define continuous vars, subset flowdata and save as CSV\n",
    "\n",
    "contvars <- names(flowdata_csv) %in% c(\"StartTime\", \"Proto\", \"SrcAddr\", \"Sport\", \"Dir\", \"DstAddr\", \"Dport\", \"State\", \"sTos\", \"dTos\")\n",
    "flowdata_conts <- flowdata_csv[!contvars]\n",
    "\n",
    "str(flowdata_conts)\n",
    "\n",
    "# Write out to csv file for persistence\n",
    "\n",
    "write.csv(flowdata_conts, file='flowdata_conts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "\n",
    "cont_vars <- c(\"Dur\", \"TotPkts\", \"TotBytes\", \"SrcBytes\")\n",
    "\n",
    "flowdata_conts <- flowdata_conts %>% mutate_each_(funs(normalize), vars = cont_vars)\n",
    "\n",
    "# Clean flowdata_conts, totally hacky but dataframe transforms are crazy fast and scale well\n",
    "\n",
    "flowdata_conts <- flowdata_conts[!(flowdata_conts$Dur == 0),]\n",
    "flowdata_conts <- flowdata_conts[!(flowdata_conts$TotPkts == 0),]\n",
    "flowdata_conts <- flowdata_conts[!(flowdata_conts$TotBytes == 0),]\n",
    "flowdata_conts <- flowdata_conts[!(flowdata_conts$SrcBytes == 0),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Re-factor-fy variable\n",
    "\n",
    "flowdata_conts$Label <- as.factor(flowdata_conts$Label)\n",
    "\n",
    "# Set randomization seed\n",
    "\n",
    "set.seed(1234)\n",
    "\n",
    "# Break dataset into training and test sets\n",
    "## split dataset randomly with a 67/33% distribution\n",
    "\n",
    "ind <- sample(2, nrow(flowdata_conts), replace=TRUE, prob=c(0.67, 0.33))\n",
    "\n",
    "flowdata_training <- flowdata_conts[ind==1,]\n",
    "flowdata_test <- flowdata_conts[ind==2,]\n",
    "\n",
    "#flowdata_training_classes <- flowdata_conts[ind==1,5]\n",
    "#flowdata_test_classes <- flowdata_conts[ind==2,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display label distribution in datasets\n",
    "\n",
    "ft_orig <- frqtab(flowdata_conts$Label)\n",
    "label_freq <- pander(ft_orig, style=\"rmarkdown\", caption=\"Original Label Frequency (%)\")\n",
    "\n",
    "ft_train <- frqtab(flowdata_training$Label)\n",
    "ft_test <- frqtab(flowdata_test$Label)\n",
    "ftcmp_df <- as.data.frame(cbind(ft_orig, ft_train, ft_test))\n",
    "colnames(ftcmp_df) <- c(\"Original\", \"Training Set\", \"Test Set\")\n",
    "pander(ftcmp_df, style=\"rmarkdown\",\n",
    "              caption=\"Comparison of Label frequencies ( in %)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NA omit after cleaning\n",
    "flowdata_test <- na.omit(flowdata_test)\n",
    "flowdata_training <- na.omit(flowdata_training)\n",
    "\n",
    "set.seed(123)\n",
    "\n",
    "# Create list for seed used with parallelization\n",
    "\n",
    "seeds <- vector(mode = \"list\", length = 51)\n",
    "for (i in 1:50) seeds[[i]] <- sample.int(1000, 22)\n",
    "\n",
    "# Used for last model\n",
    "    \n",
    "seeds[[51]] <- sample.int(1000, 1)\n",
    "\n",
    "# Define training parameters\n",
    "    \n",
    "ctrl <- trainControl(method=\"repeatedcv\", repeats=3, seeds = seeds)\n",
    "\n",
    "# Run training! LET THE COMPUTER OVERLORD LEARN\n",
    "    \n",
    "system.time(\n",
    "knnFit1 <- train(Label ~., flowdata_training, method=\"knn\",\n",
    "                trControl = ctrl, tuneLength = 10, preProcess = c(\"scale\", \"center\", \"pca\"))\n",
    ")\n",
    "\n",
    "# Output stats TODO : convert to markdown for web / slide view\n",
    "\n",
    "knnFit1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(knnFit1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run prediction over test dataset\n",
    "system.time(\n",
    "knnPredict1 <- predict(knnFit1, newdata = flowdata_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(knnPredict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate confusion matric for prediction accuracy\n",
    "cmat1 <- confusionMatrix(knnPredict1, flowdata_test$Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# render plot\n",
    "# we use three different layers\n",
    "# first we draw tiles and fill color based on percentage of test cases\n",
    "tile <- ggplot() +\n",
    "geom_tile(aes(x=Actual, y=Predicted,fill=Percent),data=cmat1, color=\"black\",size=0.1) +\n",
    "labs(x=\"Actual\",y=\"Predicted\")\n",
    "tile = tile + \n",
    "geom_text(aes(x=Actual,y=Predicted, label=sprintf(\"%.1f\", Percent)),data=cmat1, size=3, colour=\"black\") +\n",
    "scale_fill_gradient(low=\"grey\",high=\"red\")\n",
    " \n",
    "# lastly we draw diagonal tiles. We use alpha = 0 so as not to hide previous layers but use size=0.3 to highlight border\n",
    "tile = tile + \n",
    "geom_tile(aes(x=Actual,y=Predicted),data=subset(cmat1, as.character(Actual)==as.character(Predicted)), color=\"black\",size=0.3, fill=\"black\", alpha=0) \n",
    " \n",
    "#render\n",
    "tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
